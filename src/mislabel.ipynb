{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-11-19 18:35:24,058 - GDC - INFO] scores are {'RandomForestClassifier': [0.8740203193033381, 0.8740203193033381, 0.8740203193033381, 0.8740203193033381, 0.8947368421052632]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RandomForestClassifier']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# copyright: yueshi@usc.edu\n",
    "import pandas as pd \n",
    "import hashlib\n",
    "import os \n",
    "from utils import logger\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from utils import logger\n",
    "#def lassoSelection(X,y,)\n",
    "\n",
    "def lassoSelection(X_train, y_train, n):\n",
    "\t'''\n",
    "\tLasso feature selection.  Select n features. \n",
    "\t'''\n",
    "\t#lasso feature selection\n",
    "\t#print (X_train)\n",
    "\t#50 feathers\n",
    "\t#return [8, 10, 26, 78, 88, 119, 180, 195, 204, 232, 240, 248, 270, 273, 286, 296, 305, 306, 325, 329, 352, 482, 496, 497, 498, 500, 515, 539, 588, 595, 615, 884, 991, 1072, 1148, 1251, 1316, 1337, 1362, 1364, 1369, 1461, 1504, 1665, 1722, 1750, 1834, 1848, 1872, 1875]\n",
    "\t#80 feathers\n",
    "\t#return [5, 8, 10, 26, 78, 88, 119, 141, 180, 191, 194, 195, 204, 232, 240, 248, 270, 273, 286, 296, 302, 305, 306, 325, 327, 329, 339, 344, 352, 477, 482, 492, 495, 496, 497, 498, 500, 515, 539, 588, 595, 615, 638, 646, 680, 847, 884, 911, 969, 991, 1072, 1078, 1102, 1148, 1251, 1289, 1316, 1337, 1342, 1362, 1364, 1369, 1395, 1461, 1504, 1509, 1644, 1665, 1677, 1717, 1722, 1750, 1771, 1791, 1834, 1848, 1872, 1875, 1879]\n",
    "\t#190 feature\n",
    "\treturn [4, 5, 8, 10, 13, 26, 49, 72, 78, 88, 90, 92, 93, 119, 141, 175, 180, 191, 194, 195, 201, 203, 204, 229, 232, 233, 239, 240, 245, 248, 249, 255, 264, 266, 270, 272, 273, 286, 296, 299, 302, 304, 305, 306, 309, 325, 327, 329, 332, 339, 344, 352, 381, 387, 406, 426, 429, 448, 458, 464, 470, 477, 482, 483, 492, 493, 495, 496, 497, 498, 500, 503, 505, 513, 514, 515, 532, 539, 544, 566, 588, 593, 595, 615, 623, 633, 638, 645, 646, 676, 677, 680, 692, 710, 764, 777, 784, 810, 813, 814, 834, 836, 847, 860, 880, 884, 888, 894, 900, 907, 911, 950, 957, 958, 969, 991, 996, 1004, 1038, 1041, 1048, 1063, 1072, 1078, 1079, 1091, 1102, 1111, 1135, 1141, 1148, 1152, 1232, 1251, 1267, 1274, 1289, 1305, 1316, 1337, 1342, 1362, 1363, 1364, 1369, 1376, 1378, 1387, 1395, 1402, 1406, 1410, 1412, 1447, 1461, 1475, 1487, 1504, 1507, 1509, 1516, 1524, 1544, 1546, 1560, 1584, 1588, 1638, 1644, 1665, 1677, 1695, 1717, 1720, 1722, 1733, 1747, 1750, 1771, 1786, 1791, 1834, 1843, 1848, 1859, 1860, 1872, 1874, 1875, 1879]\n",
    "\tclf = LassoCV()\n",
    "\tsfm = SelectFromModel(clf, threshold=0)\n",
    "\tsfm.fit(X_train, y_train)\n",
    "\tX_transform = sfm.transform(X_train)\n",
    "\tn_features = X_transform.shape[1]\n",
    "\t#return [5, 8, 10, 26, 78, 88, 92, 119, 141, 180, 191, 194, 195, 201, 204, 229, 232, 233, 240, 248, 249, 255, 270, 272, 273, 286, 296, 299, 302, 305, 306, 309, 325, 327, 329, 332, 339, 344, 352, 387, 429, 458, 477, 482, 483, 492, 495, 496, 497, 498, 500, 505, 515, 539, 588, 595, 615, 638, 645, 646, 680, 692, 764, 834, 847, 860, 880, 884, 888, 894, 911, 957, 958, 969, 991, 1041, 1063, 1072, 1078, 1079, 1091, 1102, 1111, 1135, 1148, 1152, 1251, 1274, 1289, 1305, 1316, 1337, 1342, 1362, 1363, 1364, 1369, 1395, 1410, 1447, 1461, 1504, 1509, 1544, 1560, 1644, 1665, 1677, 1717, 1720, 1722, 1750, 1771, 1791, 1834, 1848, 1860, 1872, 1874, 1875, 1879]\n",
    "        #return [5, 8, 10, 26, 78, 88, 119, 141, 180, 191, 194, 195, 204, 232, 240, 248, 270, 273, 286, 296, 302, 305, 306, 325, 327, 329, 339, 344, 352, 477, 482, 492, 495, 496, 497, 498, 500, 515, 539, 588, 595, 615, 638, 646, 680, 847, 884, 911, 969, 991, 1072, 1078, 1102, 1148, 1251, 1289, 1316, 1337, 1342, 1362, 1364, 1369, 1395, 1461, 1504, 1509, 1644, 1665, 1677, 1717, 1722, 1750, 1771, 1791, 1834, 1848, 1872, 1875, 1879]\n",
    "\t#print(n_features)\n",
    "\twhile n_features > n:\n",
    "\t\tsfm.threshold += 0.01\n",
    "\t\tX_transform = sfm.transform(X_train)\n",
    "\t\tn_features = X_transform.shape[1]\n",
    "\tfeatures = [index for index,value in enumerate(sfm.get_support()) if value == True  ]\n",
    "\tlogger.info(\"selected features are {}\".format(features))\n",
    "\treturn features\n",
    "\n",
    "\n",
    "def specificity_score(y_true, y_predict):\n",
    "\t'''\n",
    "\ttrue_negative rate\n",
    "\t'''\n",
    "\ttrue_negative = len([index for index,pair in enumerate(zip(y_true,y_predict)) if pair[0]==pair[1] and pair[0]==0 ])\n",
    "\treal_negative = np.count_nonzero(y_true == 0)\n",
    "\t#real_negative = len(y_true) - sum(y_true)\n",
    "\treturn true_negative / real_negative \n",
    "\n",
    "def model_fit_predict(X_train,X_test,y_train,y_test):\n",
    "\n",
    "\tnp.random.seed(201)\n",
    "\tfrom sklearn.linear_model import LogisticRegression\n",
    "\tfrom sklearn.ensemble import RandomForestClassifier\n",
    "\tfrom sklearn.ensemble import AdaBoostClassifier\n",
    "\tfrom sklearn.ensemble import GradientBoostingClassifier\n",
    "\tfrom sklearn.ensemble import ExtraTreesClassifier\n",
    "\tfrom sklearn.svm import SVC\n",
    "\tfrom sklearn.metrics import precision_score\n",
    "\tfrom sklearn.metrics import accuracy_score\n",
    "\tfrom sklearn.metrics import f1_score\n",
    "\tfrom sklearn.metrics import recall_score\n",
    "\tmodels = {\n",
    "\t#\t'LogisticRegression': LogisticRegression(),\n",
    "\t#\t'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "\t\t'RandomForestClassifier': RandomForestClassifier(),\n",
    "    \t#'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    \t#'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    \t#'SVC': SVC()\n",
    "\t}\n",
    "\ttuned_parameters = {\n",
    "\t#\t'LogisticRegression':{'C': [1, 10]},\n",
    "\t#\t'ExtraTreesClassifier': { 'n_estimators': [16, 32] },\n",
    "\t\t'RandomForestClassifier': { 'n_estimators': [100, 500] },\n",
    "    \t#'AdaBoostClassifier': { 'n_estimators': [16, 32] },\n",
    "    \t#'GradientBoostingClassifier': { 'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] },\n",
    "    \t#'SVC': {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "\t}\n",
    "\tscores= {}\n",
    "\tfor key in models:\n",
    "\t\tprint (key)\n",
    "\t\tclf = GridSearchCV(models[key], tuned_parameters[key], scoring=None,  refit=True, cv=10)\n",
    "\t\t#print (clf.best_params_)\n",
    "\t\tclf.fit(X_train,y_train)\n",
    "\t\tprint (clf.best_params_)\n",
    "\t\ty_test_predict = clf.predict(X_test)\n",
    "\t\tprecision = precision_score(y_test, y_test_predict, average='micro')\n",
    "\t\taccuracy = accuracy_score(y_test, y_test_predict)\n",
    "\t\tf1 = f1_score(y_test, y_test_predict,average='micro')\n",
    "\t\trecall = recall_score(y_test, y_test_predict,average='micro')\n",
    "\t\tspecificity = specificity_score(y_test, y_test_predict)\n",
    "\t\tscores[key] = [precision,accuracy,f1,recall,specificity]\n",
    "\t#print(scores)\n",
    "\treturn scores\n",
    "\n",
    "\n",
    "\n",
    "def draw(scores):\n",
    "\t'''\n",
    "\tdraw scores.\n",
    "\t'''\n",
    "\timport matplotlib.pyplot as plt\n",
    "\tlogger.info(\"scores are {}\".format(scores))\n",
    "\tax = plt.subplot(111)\n",
    "\tprecisions = []\n",
    "\taccuracies =[]\n",
    "\tf1_scores = []\n",
    "\trecalls = []\n",
    "\tcategories = []\n",
    "\tspecificities = []\n",
    "\tN = len(scores)\n",
    "\tind = np.arange(N)  # set the x locations for the groups\n",
    "\twidth = 0.1        # the width of the bars\n",
    "\tfor key in scores:\n",
    "\t\tcategories.append(key)\n",
    "\t\tprecisions.append(scores[key][0])\n",
    "\t\taccuracies.append(scores[key][1])\n",
    "\t\tf1_scores.append(scores[key][2])\n",
    "\t\trecalls.append(scores[key][3])\n",
    "\t\tspecificities.append(scores[key][4])\n",
    "\n",
    "\tprecision_bar = ax.bar(ind, precisions,width=0.1,color='b',align='center')\n",
    "\taccuracy_bar = ax.bar(ind+1*width, accuracies,width=0.1,color='g',align='center')\n",
    "\tf1_bar = ax.bar(ind+2*width, f1_scores,width=0.1,color='r',align='center')\n",
    "\trecall_bar = ax.bar(ind+3*width, recalls,width=0.1,color='y',align='center')\n",
    "\tspecificity_bar = ax.bar(ind+4*width,specificities,width=0.1,color='purple',align='center')\n",
    "\n",
    "\tprint(categories)\n",
    "\tax.set_xticks(np.arange(N))\n",
    "\tax.set_xticklabels(categories)\n",
    "\tax.legend((precision_bar[0], accuracy_bar[0],f1_bar[0],recall_bar[0],specificity_bar[0]), ('precision', 'accuracy','f1','sensitivity','specificity'))\n",
    "\tax.grid()\n",
    "\tplt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "\tdata_dir =\"../data/\"\n",
    "\n",
    "\tdata_file = data_dir + \"miRNA_matrix.csv\"\n",
    "\n",
    "\tdf = pd.read_csv(data_file)\n",
    "\t# print(df)\n",
    "    #df.loc[df['label']==]\n",
    "\ty_data = df.pop('label').values\n",
    "\n",
    "\tdf.pop('file_id')\n",
    "\n",
    "\tcolumns =df.columns\n",
    "\t#print (columns)\n",
    "\tX_data = df.values\n",
    "\t\n",
    "\t# split the data to train and test set\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=0)\n",
    "\t\n",
    "\n",
    "\t#standardize the data.\n",
    "\tscaler = StandardScaler()\n",
    "\tscaler.fit(X_train)\n",
    "\tX_train = scaler.transform(X_train)\n",
    "\tX_test = scaler.transform(X_test)\n",
    "\n",
    "\t# check the distribution of tumor and normal sampels in traing and test data set.\n",
    "\ttrain_tumor_count = np.count_nonzero(y_train > 0)\n",
    "\ttest_tumor_count = np.count_nonzero(y_test > 0)\n",
    "\tn = 200\n",
    "\tfeaures_columns = lassoSelection(X_train, y_train, n)\n",
    "\n",
    "\n",
    "\n",
    "\tscores = model_fit_predict(X_train[:,feaures_columns],X_test[:,feaures_columns],y_train,y_test)\n",
    "\n",
    "\tdraw(scores)\n",
    "\t#lasso cross validation\n",
    "\t# lassoreg = Lasso(random_state=0)\n",
    "\t# alphas = np.logspace(-4, -0.5, 30)\n",
    "\t# tuned_parameters = [{'alpha': alphas}]\n",
    "\t# n_fold = 10\n",
    "\t# clf = GridSearchCV(lassoreg,tuned_parameters,cv=10, refit = False)\n",
    "\t# clf.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
